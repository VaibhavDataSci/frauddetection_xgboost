[
  {
    "title": "Calibration-Aware Prompt Learning for Medical Vision-Language Models",
    "abstract": "Medical Vision-Language Models (Med-VLMs) have demonstrated remarkable\nperformance across diverse medical imaging tasks by leveraging large-scale\nimage-text pretraining. However, their confidence calibration is largely\nunexplored, and so remains a significant challenge. As such, miscalibrated\npredictions can lead to overconfident errors, undermining clinical trust and\ndecision-making reliability. To address this, we introduce CalibPrompt, the\nfirst framework to calibrate Med-VLMs during prompt tuning. CalibPrompt\noptimizes a small set of learnable prompts with carefully designed calibration\nobjectives under scarce labeled data regime. First, we study a regularizer that\nattempts to align the smoothed accuracy with the predicted model confidences.\nSecond, we introduce an angular separation loss to maximize textual feature\nproximity toward improving the reliability in confidence estimates of\nmultimodal Med-VLMs. Extensive experiments on four publicly available Med-VLMs\nand five diverse medical imaging datasets reveal that CalibPrompt consistently\nimproves calibration without drastically affecting clean accuracy. Our code is\navailable at https://github.com/iabh1shekbasu/CalibPrompt.",
    "url": "http://arxiv.org/abs/2509.15226v1"
  },
  {
    "title": "Depth AnyEvent: A Cross-Modal Distillation Paradigm for Event-Based Monocular Depth Estimation",
    "abstract": "Event cameras capture sparse, high-temporal-resolution visual information,\nmaking them particularly suitable for challenging environments with high-speed\nmotion and strongly varying lighting conditions. However, the lack of large\ndatasets with dense ground-truth depth annotations hinders learning-based\nmonocular depth estimation from event data. To address this limitation, we\npropose a cross-modal distillation paradigm to generate dense proxy labels\nleveraging a Vision Foundation Model (VFM). Our strategy requires an event\nstream spatially aligned with RGB frames, a simple setup even available\noff-the-shelf, and exploits the robustness of large-scale VFMs. Additionally,\nwe propose to adapt VFMs, either a vanilla one like Depth Anything v2 (DAv2),\nor deriving from it a novel recurrent architecture to infer depth from\nmonocular event cameras. We evaluate our approach with synthetic and real-world\ndatasets, demonstrating that i) our cross-modal paradigm achieves competitive\nperformance compared to fully supervised methods without requiring expensive\ndepth annotations, and ii) our VFM-based models achieve state-of-the-art\nperformance.",
    "url": "http://arxiv.org/abs/2509.15224v1"
  },
  {
    "title": "Lightweight and Accurate Multi-View Stereo with Confidence-Aware Diffusion Model",
    "abstract": "To reconstruct the 3D geometry from calibrated images, learning-based\nmulti-view stereo (MVS) methods typically perform multi-view depth estimation\nand then fuse depth maps into a mesh or point cloud. To improve the\ncomputational efficiency, many methods initialize a coarse depth map and then\ngradually refine it in higher resolutions. Recently, diffusion models achieve\ngreat success in generation tasks. Starting from a random noise, diffusion\nmodels gradually recover the sample with an iterative denoising process. In\nthis paper, we propose a novel MVS framework, which introduces diffusion models\nin MVS. Specifically, we formulate depth refinement as a conditional diffusion\nprocess. Considering the discriminative characteristic of depth estimation, we\ndesign a condition encoder to guide the diffusion process. To improve\nefficiency, we propose a novel diffusion network combining lightweight 2D U-Net\nand convolutional GRU. Moreover, we propose a novel confidence-based sampling\nstrategy to adaptively sample depth hypotheses based on the confidence\nestimated by diffusion model. Based on our novel MVS framework, we propose two\nnovel MVS methods, DiffMVS and CasDiffMVS. DiffMVS achieves competitive\nperformance with state-of-the-art efficiency in run-time and GPU memory.\nCasDiffMVS achieves state-of-the-art performance on DTU, Tanks & Temples and\nETH3D. Code is available at: https://github.com/cvg/diffmvs.",
    "url": "http://arxiv.org/abs/2509.15220v1"
  },
  {
    "title": "Out-of-Sight Trajectories: Tracking, Fusion, and Prediction",
    "abstract": "Trajectory prediction is a critical task in computer vision and autonomous\nsystems, playing a key role in autonomous driving, robotics, surveillance, and\nvirtual reality. Existing methods often rely on complete and noise-free\nobservational data, overlooking the challenges associated with out-of-sight\nobjects and the inherent noise in sensor data caused by limited camera\ncoverage, obstructions, and the absence of ground truth for denoised\ntrajectories. These limitations pose safety risks and hinder reliable\nprediction in real-world scenarios. In this extended work, we present\nadvancements in Out-of-Sight Trajectory (OST), a novel task that predicts the\nnoise-free visual trajectories of out-of-sight objects using noisy sensor data.\nBuilding on our previous research, we broaden the scope of Out-of-Sight\nTrajectory Prediction (OOSTraj) to include pedestrians and vehicles, extending\nits applicability to autonomous driving, robotics, surveillance, and virtual\nreality. Our enhanced Vision-Positioning Denoising Module leverages camera\ncalibration to establish a vision-positioning mapping, addressing the lack of\nvisual references, while effectively denoising noisy sensor data in an\nunsupervised manner. Through extensive evaluations on the Vi-Fi and JRDB\ndatasets, our approach achieves state-of-the-art performance in both trajectory\ndenoising and prediction, significantly surpassing previous baselines.\nAdditionally, we introduce comparisons with traditional denoising methods, such\nas Kalman filtering, and adapt recent trajectory prediction models to our task,\nproviding a comprehensive benchmark. This work represents the first initiative\nto integrate vision-positioning projection for denoising noisy sensor\ntrajectories of out-of-sight agents, paving the way for future advances. The\ncode and preprocessed datasets are available at github.com/Hai-chao-Zhang/OST",
    "url": "http://arxiv.org/abs/2509.15219v1"
  },
  {
    "title": "Generalizable Geometric Image Caption Synthesis",
    "abstract": "Multimodal large language models have various practical applications that\ndemand strong reasoning abilities. Despite recent advancements, these models\nstill struggle to solve complex geometric problems. A key challenge stems from\nthe lack of high-quality image-text pair datasets for understanding geometric\nimages. Furthermore, most template-based data synthesis pipelines typically\nfail to generalize to questions beyond their predefined templates. In this\npaper, we bridge this gap by introducing a complementary process of\nReinforcement Learning with Verifiable Rewards (RLVR) into the data generation\npipeline. By adopting RLVR to refine captions for geometric images synthesized\nfrom 50 basic geometric relations and using reward signals derived from\nmathematical problem-solving tasks, our pipeline successfully captures the key\nfeatures of geometry problem-solving. This enables better task generalization\nand yields non-trivial improvements. Furthermore, even in out-of-distribution\nscenarios, the generated dataset enhances the general reasoning capabilities of\nmultimodal large language models, yielding accuracy improvements of\n$2.8\\%\\text{-}4.8\\%$ in statistics, arithmetic, algebraic, and numerical tasks\nwith non-geometric input images of MathVista and MathVerse, along with\n$2.4\\%\\text{-}3.9\\%$ improvements in Art, Design, Tech, and Engineering tasks\nin MMMU.",
    "url": "http://arxiv.org/abs/2509.15217v1"
  },
  {
    "title": "Explicit Context-Driven Neural Acoustic Modeling for High-Fidelity RIR Generation",
    "abstract": "Realistic sound simulation plays a critical role in many applications. A key\nelement in sound simulation is the room impulse response (RIR), which\ncharacterizes how sound propagates from a source to a listener within a given\nspace. Recent studies have applied neural implicit methods to learn RIR using\ncontext information collected from the environment, such as scene images.\nHowever, these approaches do not effectively leverage explicit geometric\ninformation from the environment. To further exploit the potential of neural\nimplicit models with direct geometric features, we present Mesh-infused Neural\nAcoustic Field (MiNAF), which queries a rough room mesh at given locations and\nextracts distance distributions as an explicit representation of local context.\nOur approach demonstrates that incorporating explicit local geometric features\ncan better guide the neural network in generating more accurate RIR\npredictions. Through comparisons with conventional and state-of-the-art\nbaseline methods, we show that MiNAF performs competitively across various\nevaluation metrics. Furthermore, we verify the robustness of MiNAF in datasets\nwith limited training samples, demonstrating an advance in high-fidelity sound\nsimulation.",
    "url": "http://arxiv.org/abs/2509.15210v1"
  },
  {
    "title": "FlowRL: Matching Reward Distributions for LLM Reasoning",
    "abstract": "We propose FlowRL: matching the full reward distribution via flow balancing\ninstead of maximizing rewards in large language model (LLM) reinforcement\nlearning (RL). Recent advanced reasoning models adopt reward-maximizing methods\n(\\eg, PPO and GRPO), which tend to over-optimize dominant reward signals while\nneglecting less frequent but valid reasoning paths, thus reducing diversity. In\ncontrast, we transform scalar rewards into a normalized target distribution\nusing a learnable partition function, and then minimize the reverse KL\ndivergence between the policy and the target distribution. We implement this\nidea as a flow-balanced optimization method that promotes diverse exploration\nand generalizable reasoning trajectories. We conduct experiments on math and\ncode reasoning tasks: FlowRL achieves a significant average improvement of\n$10.0\\%$ over GRPO and $5.1\\%$ over PPO on math benchmarks, and performs\nconsistently better on code reasoning tasks. These results highlight reward\ndistribution-matching as a key step toward efficient exploration and diverse\nreasoning in LLM reinforcement learning.",
    "url": "http://arxiv.org/abs/2509.15207v1"
  },
  {
    "title": "Fair-GPTQ: Bias-Aware Quantization for Large Language Models",
    "abstract": "High memory demands of generative language models have drawn attention to\nquantization, which reduces computational cost, memory usage, and latency by\nmapping model weights to lower-precision integers. Approaches such as GPTQ\neffectively minimize input-weight product errors during quantization; however,\nrecent empirical studies show that they can increase biased outputs and degrade\nperformance on fairness benchmarks, and it remains unclear which specific\nweights cause this issue. In this work, we draw new links between quantization\nand model fairness by adding explicit group-fairness constraints to the\nquantization objective and introduce Fair-GPTQ, the first quantization method\nexplicitly designed to reduce unfairness in large language models. The added\nconstraints guide the learning of the rounding operation toward less-biased\ntext generation for protected groups. Specifically, we focus on stereotype\ngeneration involving occupational bias and discriminatory language spanning\ngender, race, and religion. Fair-GPTQ has minimal impact on performance,\npreserving at least 90% of baseline accuracy on zero-shot benchmarks, reduces\nunfairness relative to a half-precision model, and retains the memory and speed\nbenefits of 4-bit quantization. We also compare the performance of Fair-GPTQ\nwith existing debiasing methods and find that it achieves performance on par\nwith the iterative null-space projection debiasing approach on\nracial-stereotype benchmarks. Overall, the results validate our theoretical\nsolution to the quantization problem with a group-bias term, highlight its\napplicability for reducing group bias at quantization time in generative\nmodels, and demonstrate that our approach can further be used to analyze\nchannel- and weight-level contributions to fairness during quantization.",
    "url": "http://arxiv.org/abs/2509.15206v1"
  },
  {
    "title": "CausalPre: Scalable and Effective Data Pre-processing for Causal Fairness",
    "abstract": "Causal fairness in databases is crucial to preventing biased and inaccurate\noutcomes in downstream tasks. While most prior work assumes a known causal\nmodel, recent efforts relax this assumption by enforcing additional\nconstraints. However, these approaches often fail to capture broader attribute\nrelationships that are critical to maintaining utility. This raises a\nfundamental question: Can we harness the benefits of causal reasoning to design\nefficient and effective fairness solutions without relying on strong\nassumptions about the underlying causal model? In this paper, we seek to answer\nthis question by introducing CausalPre, a scalable and effective\ncausality-guided data pre-processing framework that guarantees justifiable\nfairness, a strong causal notion of fairness. CausalPre extracts causally fair\nrelationships by reformulating the originally complex and computationally\ninfeasible extraction task into a tailored distribution estimation problem. To\nensure scalability, CausalPre adopts a carefully crafted variant of\nlow-dimensional marginal factorization to approximate the joint distribution,\ncomplemented by a heuristic algorithm that efficiently tackles the associated\ncomputational challenge. Extensive experiments on benchmark datasets\ndemonstrate that CausalPre is both effective and scalable, challenging the\nconventional belief that achieving causal fairness requires trading off\nrelationship coverage for relaxed model assumptions.",
    "url": "http://arxiv.org/abs/2509.15199v1"
  },
  {
    "title": "Explaining deep learning for ECG using time-localized clusters",
    "abstract": "Deep learning has significantly advanced electrocardiogram (ECG) analysis,\nenabling automatic annotation, disease screening, and prognosis beyond\ntraditional clinical capabilities. However, understanding these models remains\na challenge, limiting interpretation and gaining knowledge from these\ndevelopments. In this work, we propose a novel interpretability method for\nconvolutional neural networks applied to ECG analysis. Our approach extracts\ntime-localized clusters from the model's internal representations, segmenting\nthe ECG according to the learned characteristics while quantifying the\nuncertainty of these representations. This allows us to visualize how different\nwaveform regions contribute to the model's predictions and assess the certainty\nof its decisions. By providing a structured and interpretable view of deep\nlearning models for ECG, our method enhances trust in AI-driven diagnostics and\nfacilitates the discovery of clinically relevant electrophysiological patterns.",
    "url": "http://arxiv.org/abs/2509.15198v1"
  },
  {
    "title": "Consistent causal discovery with equal error variances: a least-squares perspective",
    "abstract": "We consider the problem of recovering the true causal structure among a set\nof variables, generated by a linear acyclic structural equation model (SEM)\nwith the error terms being independent and having equal variances. It is\nwell-known that the true underlying directed acyclic graph (DAG) encoding the\ncausal structure is uniquely identifiable under this assumption. In this work,\nwe establish that the sum of minimum expected squared errors for every\nvariable, while predicted by the best linear combination of its parent\nvariables, is minimised if and only if the causal structure is represented by\nany supergraph of the true DAG. This property is further utilised to design a\nBayesian DAG selection method that recovers the true graph consistently.",
    "url": "http://arxiv.org/abs/2509.15197v1"
  },
  {
    "title": "Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation",
    "abstract": "Large language models (LLMs) are increasingly trained with reinforcement\nlearning from verifiable rewards (RLVR), yet real-world deployment demands\nmodels that can self-improve without labels or external judges. Existing\nlabel-free methods, confidence minimization, self-consistency, or majority-vote\nobjectives, stabilize learning but steadily shrink exploration, causing an\nentropy collapse: generations become shorter, less diverse, and brittle. Unlike\nprior approaches such as Test-Time Reinforcement Learning (TTRL), which\nprimarily adapt models to the immediate unlabeled dataset at hand, our goal is\nbroader: to enable general improvements without sacrificing the model's\ninherent exploration capacity and generalization ability, i.e., evolving. We\nformalize this issue and propose EVolution-Oriented and Label-free\nReinforcement Learning (EVOL-RL), a simple rule that couples stability with\nvariation under a label-free setting. EVOL-RL keeps the majority-voted answer\nas a stable anchor (selection) while adding a novelty-aware reward that favors\nresponses whose reasoning differs from what has already been produced\n(variation), measured in semantic space. Implemented with GRPO, EVOL-RL also\nuses asymmetric clipping to preserve strong signals and an entropy regularizer\nto sustain search. This majority-for-selection + novelty-for-variation design\nprevents collapse, maintains longer and more informative chains of thought, and\nimproves both pass@1 and pass@n. EVOL-RL consistently outperforms the\nmajority-only TTRL baseline; e.g., training on label-free AIME24 lifts\nQwen3-4B-Base AIME25 pass@1 from TTRL's 4.6% to 16.4%, and pass@16 from 18.5%\nto 37.9%. EVOL-RL not only prevents diversity collapse but also unlocks\nstronger generalization across domains (e.g., GPQA). Furthermore, we\ndemonstrate that EVOL-RL also boosts performance in the RLVR setting,\nhighlighting its broad applicability.",
    "url": "http://arxiv.org/abs/2509.15194v1"
  },
  {
    "title": "TITAN: A Trajectory-Informed Technique for Adaptive Parameter Freezing in Large-Scale VQE",
    "abstract": "Variational quantum Eigensolver (VQE) is a leading candidate for harnessing\nquantum computers to advance quantum chemistry and materials simulations, yet\nits training efficiency deteriorates rapidly for large Hamiltonians. Two issues\nunderlie this bottleneck: (i) the no-cloning theorem imposes a linear growth in\ncircuit evaluations with the number of parameters per gradient step; and (ii)\ndeeper circuits encounter barren plateaus (BPs), leading to exponentially\nincreasing measurement overheads. To address these challenges, here we propose\na deep learning framework, dubbed Titan, which identifies and freezes inactive\nparameters of a given ansatze at initialization for a specific class of\nHamiltonians, reducing the optimization overhead without sacrificing accuracy.\nThe motivation of Titan starts with our empirical findings that a subset of\nparameters consistently has a negligible influence on training dynamics. Its\ndesign combines a theoretically grounded data construction strategy, ensuring\neach training example is informative and BP-resilient, with an adaptive neural\narchitecture that generalizes across ansatze of varying sizes. Across benchmark\ntransverse-field Ising models, Heisenberg models, and multiple molecule systems\nup to 30 qubits, Titan achieves up to 3 times faster convergence and 40% to 60%\nfewer circuit evaluations than state-of-the-art baselines, while matching or\nsurpassing their estimation accuracy. By proactively trimming parameter space,\nTitan lowers hardware demands and offers a scalable path toward utilizing VQE\nto advance practical quantum chemistry and materials science.",
    "url": "http://arxiv.org/abs/2509.15193v1"
  },
  {
    "title": "Channel Prediction under Network Distribution Shift Using Continual Learning-based Loss Regularization",
    "abstract": "Modern wireless networks face critical challenges when mobile users traverse\nheterogeneous network configurations with varying antenna layouts, carrier\nfrequencies, and scattering statistics. Traditional predictors degrade under\ndistribution shift, with NMSE rising by 37.5\\% during cross-configuration\nhandovers. This work addresses catastrophic forgetting in channel prediction by\nproposing a continual learning framework based on loss regularization. The\napproach augments standard training objectives with penalty terms that\nselectively preserve network parameters essential for previous configurations\nwhile enabling adaptation to new environments. Two prominent regularization\nstrategies are investigated: Elastic Weight Consolidation (EWC) and Synaptic\nIntelligence (SI). Across 3GPP scenarios and multiple architectures, SI lowers\nthe high-SNR NMSE floor by up to 1.8 dB ($\\approx$32--34\\%), while EWC achieves\nup to 1.4 dB ($\\approx$17--28\\%). Notably, standard EWC incurs\n$\\mathcal{O}(MK)$ complexity (storing $M$ Fisher diagonal entries and\ncorresponding parameter snapshots across $K$ tasks) unless consolidated,\nwhereas SI maintains $\\mathcal{O}(M)$ memory complexity (storing $M$ model\nparameters), independent of task sequence length, making it suitable for\nresource-constrained wireless infrastructure",
    "url": "http://arxiv.org/abs/2509.15192v1"
  },
  {
    "title": "Fast and Fluent Diffusion Language Models via Convolutional Decoding and Rejective Fine-tuning",
    "abstract": "Autoregressive (AR) language models generate text one token at a time, which\nlimits their inference speed. Diffusion-based language models offer a promising\nalternative, as they can decode multiple tokens in parallel. However, we\nidentify a key bottleneck in current diffusion LMs: the long decoding-window\nproblem, where tokens generated far from the input context often become\nirrelevant or repetitive. Previous solutions like semi-autoregressive address\nthis issue by splitting windows into blocks, but this sacrifices speed and\nbidirectionality, eliminating the main advantage of diffusion models. To\novercome this, we propose Convolutional decoding (Conv), a normalization-based\nmethod that narrows the decoding window without hard segmentation, leading to\nbetter fluency and flexibility. Additionally, we introduce Rejecting Rule-based\nFine-Tuning (R2FT), a post-hoc training scheme that better aligns tokens at\npositions far from context. Our methods achieve state-of-the-art results on\nopen-ended generation benchmarks (e.g., AlpacaEval) among diffusion LM\nbaselines, with significantly lower step size than previous works,\ndemonstrating both speed and quality improvements.",
    "url": "http://arxiv.org/abs/2509.15188v1"
  },
  {
    "title": "MaRVIn: A Cross-Layer Mixed-Precision RISC-V Framework for DNN Inference, from ISA Extension to Hardware Acceleration",
    "abstract": "The evolution of quantization and mixed-precision techniques has unlocked new\npossibilities for enhancing the speed and energy efficiency of NNs. Several\nrecent studies indicate that adapting precision levels across different\nparameters can maintain accuracy comparable to full-precision models while\nsignificantly reducing computational demands. However, existing embedded\nmicroprocessors lack sufficient architectural support for efficiently executing\nmixed-precision NNs, both in terms of ISA extensions and hardware design,\nresulting in inefficiencies such as excessive data packing/unpacking and\nunderutilized arithmetic units. In this work, we propose novel ISA extensions\nand a micro-architecture implementation specifically designed to optimize\nmixed-precision execution, enabling energy-efficient deep learning inference on\nRISC-V architectures. We introduce MaRVIn, a cross-layer hardware-software\nco-design framework that enhances power efficiency and performance through a\ncombination of hardware improvements, mixed-precision quantization, ISA-level\noptimizations, and cycle-accurate emulation. At the hardware level, we enhance\nthe ALU with configurable mixed-precision arithmetic (2, 4, 8 bits) for\nweights/activations and employ multi-pumping to reduce execution latency while\nimplementing soft SIMD for efficient 2-bit ops. At the software level, we\nintegrate a pruning-aware fine-tuning method to optimize model compression and\na greedy-based DSE approach to efficiently search for Pareto-optimal\nmixed-quantized models. Additionally, we incorporate voltage scaling to boost\nthe power efficiency of our system. Our experimental evaluation over widely\nused DNNs and datasets, such as CIFAR10 and ImageNet, demonstrates that our\nframework can achieve, on average, 17.6x speedup for less than 1% accuracy loss\nand outperforms the ISA-agnostic state-of-the-art RISC-V cores, delivering up\nto 1.8 TOPs/W.",
    "url": "http://arxiv.org/abs/2509.15187v1"
  },
  {
    "title": "Understand Before You Generate: Self-Guided Training for Autoregressive Image Generation",
    "abstract": "Recent studies have demonstrated the importance of high-quality visual\nrepresentations in image generation and have highlighted the limitations of\ngenerative models in image understanding. As a generative paradigm originally\ndesigned for natural language, autoregressive models face similar challenges.\nIn this work, we present the first systematic investigation into the mechanisms\nof applying the next-token prediction paradigm to the visual domain. We\nidentify three key properties that hinder the learning of high-level visual\nsemantics: local and conditional dependence, inter-step semantic inconsistency,\nand spatial invariance deficiency. We show that these issues can be effectively\naddressed by introducing self-supervised objectives during training, leading to\na novel training framework, Self-guided Training for AutoRegressive models\n(ST-AR). Without relying on pre-trained representation models, ST-AR\nsignificantly enhances the image understanding ability of autoregressive models\nand leads to improved generation quality. Specifically, ST-AR brings\napproximately 42% FID improvement for LlamaGen-L and 49% FID improvement for\nLlamaGen-XL, while maintaining the same sampling strategy.",
    "url": "http://arxiv.org/abs/2509.15185v1"
  },
  {
    "title": "Conditional Prior-based Non-stationary Channel Estimation Using Accelerated Diffusion Models",
    "abstract": "Wireless channels in motion-rich urban microcell (UMi) settings are\nnon-stationary; mobility and scatterer dynamics shift the distribution over\ntime, degrading classical and deep estimators. This work proposes conditional\nprior diffusion for channel estimation, which learns a history-conditioned\nscore to denoise noisy channel snapshots. A temporal encoder with cross-time\nattention compresses a short observation window into a context vector, which\ncaptures the channel's instantaneous coherence and steers the denoiser via\nfeature-wise modulation. In inference, an SNR-matched initialization selects\nthe diffusion step whose marginal aligns with the measured input SNR, and the\nprocess follows a shortened, geometrically spaced schedule, preserving the\nsignal-to-noise trajectory with far fewer iterations. Temporal\nself-conditioning with the previous channel estimate and a training-only\nsmoothness penalty further stabilizes evolution without biasing the test-time\nestimator. Evaluations on a 3GPP benchmark show lower NMSE across all SNRs than\nLMMSE, GMM, LSTM, and LDAMP baselines, demonstrating stable performance and\nstrong high SNR fidelity.",
    "url": "http://arxiv.org/abs/2509.15182v1"
  },
  {
    "title": "Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding",
    "abstract": "Spatio-temporal video grounding (STVG) aims at localizing the spatio-temporal\ntube of a video, as specified by the input text query. In this paper, we\nutilize multimodal large language models (MLLMs) to explore a zero-shot\nsolution in STVG. We reveal two key insights about MLLMs: (1) MLLMs tend to\ndynamically assign special tokens, referred to as \\textit{grounding tokens},\nfor grounding the text query; and (2) MLLMs often suffer from suboptimal\ngrounding due to the inability to fully integrate the cues in the text query\n(\\textit{e.g.}, attributes, actions) for inference. Based on these insights, we\npropose a MLLM-based zero-shot framework for STVG, which includes novel\ndecomposed spatio-temporal highlighting (DSTH) and temporal-augmented\nassembling (TAS) strategies to unleash the reasoning ability of MLLMs. The DSTH\nstrategy first decouples the original query into attribute and action\nsub-queries for inquiring the existence of the target both spatially and\ntemporally. It then uses a novel logit-guided re-attention (LRA) module to\nlearn latent variables as spatial and temporal prompts, by regularizing token\npredictions for each sub-query. These prompts highlight attribute and action\ncues, respectively, directing the model's attention to reliable spatial and\ntemporal related visual regions. In addition, as the spatial grounding by the\nattribute sub-query should be temporally consistent, we introduce the TAS\nstrategy to assemble the predictions using the original video frames and the\ntemporal-augmented frames as inputs to help improve temporal consistency. We\nevaluate our method on various MLLMs, and show that it outperforms SOTA methods\non three common STVG benchmarks.\n  The code will be available at https://github.com/zaiquanyang/LLaVA_Next_STVG.",
    "url": "http://arxiv.org/abs/2509.15178v1"
  },
  {
    "title": "Internalizing Self-Consistency in Language Models: Multi-Agent Consensus Alignment",
    "abstract": "Language Models (LMs) are inconsistent reasoners, often generating\ncontradictory responses to identical prompts. While inference-time methods can\nmitigate these inconsistencies, they fail to address the core problem: LMs\nstruggle to reliably select reasoning pathways leading to consistent outcomes\nunder exploratory sampling. To address this, we formalize self-consistency as\nan intrinsic property of well-aligned reasoning models and introduce\nMulti-Agent Consensus Alignment (MACA), a reinforcement learning framework that\npost-trains models to favor reasoning trajectories aligned with their internal\nconsensus using majority/minority outcomes from multi-agent debate. These\ntrajectories emerge from deliberative exchanges where agents ground reasoning\nin peer arguments, not just aggregation of independent attempts, creating\nricher consensus signals than single-round majority voting. MACA enables agents\nto teach themselves to be more decisive and concise, and better leverage peer\ninsights in multi-agent settings without external supervision, driving\nsubstantial improvements across self-consistency (+27.6% on GSM8K),\nsingle-agent reasoning (+23.7% on MATH), sampling-based inference (+22.4%\nPass@20 on MATH), and multi-agent ensemble decision-making (+42.7% on MathQA).\nThese findings, coupled with strong generalization to unseen benchmarks (+16.3%\non GPQA, +11.6% on CommonsenseQA), demonstrate robust self-alignment that more\nreliably unlocks latent reasoning potential of language models.",
    "url": "http://arxiv.org/abs/2509.15172v1"
  },
  {
    "title": "Watermarking and Anomaly Detection in Machine Learning Models for LORA RF Fingerprinting",
    "abstract": "Radio frequency fingerprint identification (RFFI) distinguishes wireless\ndevices by the small variations in their analog circuits, avoiding heavy\ncryptographic authentication. While deep learning on spectrograms improves\naccuracy, models remain vulnerable to copying, tampering, and evasion. We\npresent a stronger RFFI system combining watermarking for ownership proof and\nanomaly detection for spotting suspicious inputs. Using a ResNet-34 on log-Mel\nspectrograms, we embed three watermarks: a simple trigger, an adversarially\ntrained trigger robust to noise and filtering, and a hidden gradient/weight\nsignature. A convolutional Variational Autoencoders (VAE) with Kullback-Leibler\n(KL) warm-up and free-bits flags off-distribution queries. On the LoRa dataset,\nour system achieves 94.6% accuracy, 98% watermark success, and 0.94 AUROC,\noffering verifiable, tamper-resistant authentication.",
    "url": "http://arxiv.org/abs/2509.15170v1"
  },
  {
    "title": "Semi-Supervised 3D Medical Segmentation from 2D Natural Images Pretrained Model",
    "abstract": "This paper explores the transfer of knowledge from general vision models\npretrained on 2D natural images to improve 3D medical image segmentation. We\nfocus on the semi-supervised setting, where only a few labeled 3D medical\nimages are available, along with a large set of unlabeled images. To tackle\nthis, we propose a model-agnostic framework that progressively distills\nknowledge from a 2D pretrained model to a 3D segmentation model trained from\nscratch. Our approach, M&N, involves iterative co-training of the two models\nusing pseudo-masks generated by each other, along with our proposed learning\nrate guided sampling that adaptively adjusts the proportion of labeled and\nunlabeled data in each training batch to align with the models' prediction\naccuracy and stability, minimizing the adverse effect caused by inaccurate\npseudo-masks. Extensive experiments on multiple publicly available datasets\ndemonstrate that M&N achieves state-of-the-art performance, outperforming\nthirteen existing semi-supervised segmentation approaches under all different\nsettings. Importantly, ablation studies show that M&N remains model-agnostic,\nallowing seamless integration with different architectures. This ensures its\nadaptability as more advanced models emerge. The code is available at\nhttps://github.com/pakheiyeung/M-N.",
    "url": "http://arxiv.org/abs/2509.15167v1"
  },
  {
    "title": "A Unified Distributed Algorithm for Hybrid Near-Far Field Activity Detection in Cell-Free Massive MIMO",
    "abstract": "A great amount of endeavor has recently been devoted to activity detection\nfor massive machine-type communications in cell-free multiple-input\nmultiple-output (MIMO) systems. However, as the number of antennas at the\naccess points (APs) increases, the Rayleigh distance that separates the\nnear-field and far-field regions also expands, rendering the conventional\nassumption of far-field propagation alone impractical. To address this\nchallenge, this paper establishes a covariance-based formulation that can\neffectively capture the statistical property of hybrid near-far field channels.\nBased on this formulation, we theoretically reveal that increasing the\nproportion of near-field channels enhances the detection performance.\nFurthermore, we propose a distributed algorithm, where each AP performs local\nactivity detection and only exchanges the detection results to the central\nprocessing unit, thus significantly reducing the computational complexity and\nthe communication overhead. Not only with convergence guarantee, the proposed\nalgorithm is unified in the sense that it can handle single-cell or cell-free\nsystems with either near-field or far-field devices as special cases.\nSimulation results validate the theoretical analyses and demonstrate the\nsuperior performance of the proposed approach compared with existing methods.",
    "url": "http://arxiv.org/abs/2509.15162v1"
  },
  {
    "title": "Mind the Gap: Data Rewriting for Stable Off-Policy Supervised Fine-Tuning",
    "abstract": "Supervised fine-tuning (SFT) of large language models can be viewed as an\noff-policy learning problem, where expert demonstrations come from a fixed\nbehavior policy while training aims to optimize a target policy. Importance\nsampling is the standard tool for correcting this distribution mismatch, but\nlarge policy gaps lead to high variance and training instability. Existing\napproaches mitigate this issue using KL penalties or clipping, which passively\nconstrain updates rather than actively reducing the gap. We propose a simple\nyet effective data rewriting framework that proactively shrinks the policy gap\nby keeping correct solutions as on-policy data and rewriting incorrect ones\nwith guided re-solving, falling back to expert demonstrations only when needed.\nThis aligns the training distribution with the target policy before\noptimization, reducing importance sampling variance and stabilizing off-policy\nfine-tuning. Experiments on five mathematical reasoning benchmarks demonstrate\nconsistent and significant gains over both vanilla SFT and the state-of-the-art\nDynamic Fine-Tuning (DFT) approach. The data and code will be released at\nhttps://github.com/NKU-HLT/Off-Policy-SFT.",
    "url": "http://arxiv.org/abs/2509.15157v1"
  },
  {
    "title": "Leveraging Geometric Visual Illusions as Perceptual Inductive Biases for Vision Models",
    "abstract": "Contemporary deep learning models have achieved impressive performance in\nimage classification by primarily leveraging statistical regularities within\nlarge datasets, but they rarely incorporate structured insights drawn directly\nfrom perceptual psychology. To explore the potential of perceptually motivated\ninductive biases, we propose integrating classic geometric visual illusions\nwell-studied phenomena from human perception into standard image-classification\ntraining pipelines. Specifically, we introduce a synthetic, parametric\ngeometric-illusion dataset and evaluate three multi-source learning strategies\nthat combine illusion recognition tasks with ImageNet classification\nobjectives. Our experiments reveal two key conceptual insights: (i)\nincorporating geometric illusions as auxiliary supervision systematically\nimproves generalization, especially in visually challenging cases involving\nintricate contours and fine textures; and (ii) perceptually driven inductive\nbiases, even when derived from synthetic stimuli traditionally considered\nunrelated to natural image recognition, can enhance the structural sensitivity\nof both CNN and transformer-based architectures. These results demonstrate a\nnovel integration of perceptual science and machine learning and suggest new\ndirections for embedding perceptual priors into vision model design.",
    "url": "http://arxiv.org/abs/2509.15156v1"
  },
  {
    "title": "Self-Improving Embodied Foundation Models",
    "abstract": "Foundation models trained on web-scale data have revolutionized robotics, but\ntheir application to low-level control remains largely limited to behavioral\ncloning. Drawing inspiration from the success of the reinforcement learning\nstage in fine-tuning large language models, we propose a two-stage\npost-training approach for robotics. The first stage, Supervised Fine-Tuning\n(SFT), fine-tunes pretrained foundation models using both: a) behavioral\ncloning, and b) steps-to-go prediction objectives. In the second stage,\nSelf-Improvement, steps-to-go prediction enables the extraction of a\nwell-shaped reward function and a robust success detector, enabling a fleet of\nrobots to autonomously practice downstream tasks with minimal human\nsupervision. Through extensive experiments on real-world and simulated robot\nembodiments, our novel post-training recipe unveils significant results on\nEmbodied Foundation Models. First, we demonstrate that the combination of SFT\nand Self-Improvement is significantly more sample-efficient than scaling\nimitation data collection for supervised learning, and that it leads to\npolicies with significantly higher success rates. Further ablations highlight\nthat the combination of web-scale pretraining and Self-Improvement is the key\nto this sample-efficiency. Next, we demonstrate that our proposed combination\nuniquely unlocks a capability that current methods cannot achieve: autonomously\npracticing and acquiring novel skills that generalize far beyond the behaviors\nobserved in the imitation learning datasets used during training. These\nfindings highlight the transformative potential of combining pretrained\nfoundation models with online Self-Improvement to enable autonomous skill\nacquisition in robotics. Our project website can be found at\nhttps://self-improving-efms.github.io .",
    "url": "http://arxiv.org/abs/2509.15155v1"
  },
  {
    "title": "MedFact-R1: Towards Factual Medical Reasoning via Pseudo-Label Augmentation",
    "abstract": "Ensuring factual consistency and reliable reasoning remains a critical\nchallenge for medical vision-language models. We introduce MEDFACT-R1, a\ntwo-stage framework that integrates external knowledge grounding with\nreinforcement learning to improve the factual medical reasoning. The first\nstage uses pseudo-label supervised fine-tuning (SFT) to incorporate external\nfactual expertise; while the second stage applies Group Relative Policy\nOptimization (GRPO) with four tailored factual reward signals to encourage\nself-consistent reasoning. Across three public medical QA benchmarks,\nMEDFACT-R1 delivers up to 22.5% absolute improvement in factual accuracy over\nprevious state-of-the-art methods. Ablation studies highlight the necessity of\npseudo-label SFT cold start and validate the contribution of each GRPO reward,\nunderscoring the synergy between knowledge grounding and RL-driven reasoning\nfor trustworthy medical AI. Codes are released at\nhttps://github.com/Garfieldgengliang/MEDFACT-R1.",
    "url": "http://arxiv.org/abs/2509.15154v1"
  },
  {
    "title": "AnoF-Diff: One-Step Diffusion-Based Anomaly Detection for Forceful Tool Use",
    "abstract": "Multivariate time-series anomaly detection, which is critical for identifying\nunexpected events, has been explored in the field of machine learning for\nseveral decades. However, directly applying these methods to data from forceful\ntool use tasks is challenging because streaming sensor data in the real world\ntends to be inherently noisy, exhibits non-stationary behavior, and varies\nacross different tasks and tools. To address these challenges, we propose a\nmethod, AnoF-Diff, based on the diffusion model to extract force-torque\nfeatures from time-series data and use force-torque features to detect\nanomalies. We compare our method with other state-of-the-art methods in terms\nof F1-score and Area Under the Receiver Operating Characteristic curve (AUROC)\non four forceful tool-use tasks, demonstrating that our method has better\nperformance and is more robust to a noisy dataset. We also propose the method\nof parallel anomaly score evaluation based on one-step diffusion and\ndemonstrate how our method can be used for online anomaly detection in several\nforceful tool use experiments.",
    "url": "http://arxiv.org/abs/2509.15153v1"
  },
  {
    "title": "Asymptotic Study of In-context Learning with Random Transformers through Equivalent Models",
    "abstract": "We study the in-context learning (ICL) capabilities of pretrained\nTransformers in the setting of nonlinear regression. Specifically, we focus on\na random Transformer with a nonlinear MLP head where the first layer is\nrandomly initialized and fixed while the second layer is trained. Furthermore,\nwe consider an asymptotic regime where the context length, input dimension,\nhidden dimension, number of training tasks, and number of training samples\njointly grow. In this setting, we show that the random Transformer behaves\nequivalent to a finite-degree Hermite polynomial model in terms of ICL error.\nThis equivalence is validated through simulations across varying activation\nfunctions, context lengths, hidden layer widths (revealing a double-descent\nphenomenon), and regularization settings. Our results offer theoretical and\nempirical insights into when and how MLP layers enhance ICL, and how\nnonlinearity and over-parameterization influence model performance.",
    "url": "http://arxiv.org/abs/2509.15152v1"
  },
  {
    "title": "Exploring How Audio Effects Alter Emotion with Foundation Models",
    "abstract": "Audio effects (FX) such as reverberation, distortion, modulation, and dynamic\nrange processing play a pivotal role in shaping emotional responses during\nmusic listening. While prior studies have examined links between low-level\naudio features and affective perception, the systematic impact of audio FX on\nemotion remains underexplored. This work investigates how foundation models -\nlarge-scale neural architectures pretrained on multimodal data - can be\nleveraged to analyze these effects. Such models encode rich associations\nbetween musical structure, timbre, and affective meaning, offering a powerful\nframework for probing the emotional consequences of sound design techniques. By\napplying various probing methods to embeddings from deep learning models, we\nexamine the complex, nonlinear relationships between audio FX and estimated\nemotion, uncovering patterns tied to specific effects and evaluating the\nrobustness of foundation audio models. Our findings aim to advance\nunderstanding of the perceptual impact of audio production practices, with\nimplications for music cognition, performance, and affective computing.",
    "url": "http://arxiv.org/abs/2509.15151v1"
  },
  {
    "title": "Who to Trust? Aggregating Client Knowledge in Logit-Based Federated Learning",
    "abstract": "Federated learning (FL) usually shares model weights or gradients, which is\ncostly for large models. Logit-based FL reduces this cost by sharing only\nlogits computed on a public proxy dataset. However, aggregating information\nfrom heterogeneous clients is still challenging. This paper studies this\nproblem, introduces and compares three logit aggregation methods: simple\naveraging, uncertainty-weighted averaging, and a learned meta-aggregator.\nEvaluated on MNIST and CIFAR-10, these methods reduce communication overhead,\nimprove robustness under non-IID data, and achieve accuracy competitive with\ncentralized training.",
    "url": "http://arxiv.org/abs/2509.15147v1"
  },
  {
    "title": "Optimal Learning from Label Proportions with General Loss Functions",
    "abstract": "Motivated by problems in online advertising, we address the task of Learning\nfrom Label Proportions (LLP). In this partially-supervised setting, training\ndata consists of groups of examples, termed bags, for which we only observe the\naverage label value. The main goal, however, remains the design of a predictor\nfor the labels of individual examples. We introduce a novel and versatile\nlow-variance de-biasing methodology to learn from aggregate label information,\nsignificantly advancing the state of the art in LLP. Our approach exhibits\nremarkable flexibility, seamlessly accommodating a broad spectrum of\npractically relevant loss functions across both binary and multi-class\nclassification settings. By carefully combining our estimators with standard\ntechniques, we substantially improve sample complexity guarantees for a large\nclass of losses of practical relevance. We also empirically validate the\nefficacy of our proposed approach across a diverse array of benchmark datasets,\ndemonstrating compelling empirical advantages over standard baselines.",
    "url": "http://arxiv.org/abs/2509.15145v1"
  },
  {
    "title": "Next-Depth Lookahead Tree",
    "abstract": "This paper proposes the Next-Depth Lookahead Tree (NDLT), a single-tree model\ndesigned to improve performance by evaluating node splits not only at the node\nbeing optimized but also by evaluating the quality of the next depth level.",
    "url": "http://arxiv.org/abs/2509.15143v1"
  },
  {
    "title": "Benefits of Online Tilted Empirical Risk Minimization: A Case Study of Outlier Detection and Robust Regression",
    "abstract": "Empirical Risk Minimization (ERM) is a foundational framework for supervised\nlearning but primarily optimizes average-case performance, often neglecting\nfairness and robustness considerations. Tilted Empirical Risk Minimization\n(TERM) extends ERM by introducing an exponential tilt hyperparameter $t$ to\nbalance average-case accuracy with worst-case fairness and robustness. However,\nin online or streaming settings where data arrive one sample at a time, the\nclassical TERM objective degenerates to standard ERM, losing tilt sensitivity.\nWe address this limitation by proposing an online TERM formulation that removes\nthe logarithm from the classical objective, preserving tilt effects without\nadditional computational or memory overhead. This formulation enables a\ncontinuous trade-off controlled by $t$, smoothly interpolating between ERM ($t\n\\to 0$), fairness emphasis ($t > 0$), and robustness to outliers ($t < 0$). We\nempirically validate online TERM on two representative streaming tasks: robust\nlinear regression with adversarial outliers and minority-class detection in\nbinary classification. Our results demonstrate that negative tilting\neffectively suppresses outlier influence, while positive tilting improves\nrecall with minimal impact on precision, all at per-sample computational cost\nequivalent to ERM. Online TERM thus recovers the full robustness-fairness\nspectrum of classical TERM in an efficient single-sample learning regime.",
    "url": "http://arxiv.org/abs/2509.15141v1"
  },
  {
    "title": "A model-independent measurement of the CKM angle $\u03b3$ in the decays $B^\\pm\\to[K^+K^-\u03c0^+\u03c0^-]_D h^\\pm$ and $B^\\pm\\to[\u03c0^+\u03c0^-\u03c0^+\u03c0^-]_D h^\\pm$ ($h = K, \u03c0$)",
    "abstract": "A model-independent determination of the CKM angle $\\gamma$ is presented,\nusing the $B^\\pm\\to[K^+K^-\\pi^+\\pi^-]_D h^\\pm$ and\n$B^\\pm\\to[\\pi^+\\pi^-\\pi^+\\pi^-]_D h^\\pm$ decays, with $h=K,\\pi$. This\nmeasurement is the first phase-space-binned study of these decay modes, and\nuses a sample of proton-proton collision data collected by the LHCb experiment,\ncorresponding to an integrated luminosity of $9$fb$^{-1}$. The phase-space bins\nare optimised for sensitivity to $\\gamma$, and in each bin external inputs from\nthe BESIII experiment are used to constrain the charm strong-phase parameters.\nThe result of this binned analysis is $\\gamma = (53.9_{-8.9}^{+9.5})^\\circ$,\nwhere the uncertainty includes both statistical and systematic contributions.\nFurthermore, when combining with existing phase-space-integrated measurements\nof the same decay modes, a value of $\\gamma = (52.6_{-6.4}^{+8.5})^\\circ$ is\nobtained, which is one of the most precise determinations of $\\gamma$ to date.",
    "url": "http://arxiv.org/abs/2509.15139v1"
  },
  {
    "title": "Accelerated Discovery of Topological Conductors for Nanoscale Interconnects",
    "abstract": "The sharp increase in resistivity of copper interconnects at ultra-scaled\ndimensions threatens the continued miniaturization of integrated circuits.\nTopological semimetals (TSMs) with gapless surface states (Fermi arcs) provide\nconduction channels resistant to localization. Here we develop an efficient\ncomputational framework to quantify 0K surface-state transmission in nanowires\nderived from Wannier tight-binding models of topological conductors that\nfaithfully reproduce relativistic density functional theory results. Sparse\nmatrix techniques enable scalable simulations incorporating disorder and\nsurface roughness, allowing systematic materials screening across sizes,\nchemical potentials, and transport directions. A dataset of 3000 surface\ntransmission values reveals TiS, ZrB$_{2}$, and nitrides AN where A=(Mo, Ta, W)\nas candidates with conductance matching or exceeding copper and benchmark TSMs\nNbAs and NbP. This dataset further supports machine learning models for rapid\ninterconnect compound identification. Our results highlight the promise of\ntopological conductors in overcoming copper's scaling limits and provide a\nroadmap for data-driven discovery of next-generation interconnects.",
    "url": "http://arxiv.org/abs/2509.15135v1"
  },
  {
    "title": "Sequential sample size calculations and learning curves safeguard the robust development of a clinical prediction model for individuals",
    "abstract": "When prospectively developing a new clinical prediction model (CPM), fixed\nsample size calculations are typically conducted before data collection based\non sensible assumptions. But if the assumptions are inaccurate the actual\nsample size required to develop a reliable model may be very different. To\nsafeguard against this, adaptive sample size approaches have been proposed,\nbased on sequential evaluation of a models predictive performance. Aim:\nillustrate and extend sequential sample size calculations for CPM development\nby (i) proposing stopping rules based on minimising uncertainty (instability)\nand misclassification of individual-level predictions, and (ii) showcasing how\nit safeguards against inaccurate fixed sample size calculations. Using the\nsequential approach repeats the pre-defined model development strategy every\ntime a chosen number (e.g., 100) of participants are recruited and adequately\nfollowed up. At each stage, CPM performance is evaluated using bootstrapping,\nleading to prediction and classification stability statistics and plots,\nalongside optimism-adjusted measures of calibration and discrimination. Our\napproach is illustrated for development of acute kidney injury using logistic\nregression CPMs. The fixed sample size calculation, based on perceived sensible\nassumptions suggests recruiting 342 patients to minimise overfitting; however,\nthe sequential approach reveals that a much larger sample size of 1100 is\nrequired to minimise overfitting (targeting population-level stability). If the\nstopping rule criteria also target small uncertainty and misclassification\nprobability of individual predictions, the sequential approach suggests an even\nlarger sample size (n=1800). Our sequential sample size approach allows users\nto dynamically monitor individual-level prediction and classification\ninstability and safeguard against using inaccurate assumptions.",
    "url": "http://arxiv.org/abs/2509.15134v1"
  },
  {
    "title": "Doppler Radiance Field-Guided Antenna Selection for Improved Generalization in Multi-Antenna Wi-Fi-based Human Activity Recognition",
    "abstract": "With the IEEE 802.11bf Task Group introducing amendments to the WLAN standard\nfor advanced sensing, interest in using Wi-Fi Channel State Information (CSI)\nfor remote sensing has surged. Recent findings indicate that learning a unified\nthree-dimensional motion representation through Doppler Radiance Fields (DoRFs)\nderived from CSI significantly improves the generalization capabilities of\nWi-Fi-based human activity recognition (HAR). Despite this progress, CSI\nsignals remain affected by asynchronous access point (AP) clocks and additive\nnoise from environmental and hardware sources. Consequently, even with existing\npreprocessing techniques, both the CSI data and Doppler velocity projections\nused in DoRFs are still susceptible to noise and outliers, limiting HAR\nperformance. To address this challenge, we propose a novel framework for\nmulti-antenna APs to suppress noise and identify the most informative antennas\nbased on DoRF fitting errors, which capture inconsistencies among Doppler\nvelocity projections. Experimental results on a challenging small-scale hand\ngesture recognition dataset demonstrate that the proposed DoRF-guided\nWi-Fi-based HAR approach significantly improves generalization capability,\npaving the way for robust real-world sensing deployments.",
    "url": "http://arxiv.org/abs/2509.15129v1"
  },
  {
    "title": "Learning Rate Should Scale Inversely with High-Order Data Moments in High-Dimensional Online Independent Component Analysis",
    "abstract": "We investigate the impact of high-order moments on the learning dynamics of\nan online Independent Component Analysis (ICA) algorithm under a\nhigh-dimensional data model composed of a weighted sum of two non-Gaussian\nrandom variables. This model allows precise control of the input moment\nstructure via a weighting parameter. Building on an existing ordinary\ndifferential equation (ODE)-based analysis in the high-dimensional limit, we\ndemonstrate that as the high-order moments increase, the algorithm exhibits\nslower convergence and demands both a lower learning rate and greater initial\nalignment to achieve informative solutions. Our findings highlight the\nalgorithm's sensitivity to the statistical structure of the input data,\nparticularly its moment characteristics. Furthermore, the ODE framework reveals\na critical learning rate threshold necessary for learning when moments approach\ntheir maximum. These insights motivate future directions in moment-aware\ninitialization and adaptive learning rate strategies to counteract the\ndegradation in learning speed caused by high non-Gaussianity, thereby enhancing\nthe robustness and efficiency of ICA in complex, high-dimensional settings.",
    "url": "http://arxiv.org/abs/2509.15127v1"
  },
  {
    "title": "Learning Mechanistic Subtypes of Neurodegeneration with a Physics-Informed Variational Autoencoder Mixture Model",
    "abstract": "Modelling the underlying mechanisms of neurodegenerative diseases demands\nmethods that capture heterogeneous and spatially varying dynamics from sparse,\nhigh-dimensional neuroimaging data. Integrating partial differential equation\n(PDE) based physics knowledge with machine learning provides enhanced\ninterpretability and utility over classic numerical methods. However, current\nphysics-integrated machine learning methods are limited to considering a single\nPDE, severely limiting their application to diseases where multiple mechanisms\nare responsible for different groups (i.e., subtypes) and aggravating problems\nwith model misspecification and degeneracy. Here, we present a deep generative\nmodel for learning mixtures of latent dynamic models governed by physics-based\nPDEs, going beyond traditional approaches that assume a single PDE structure.\nOur method integrates reaction-diffusion PDEs within a variational autoencoder\n(VAE) mixture model framework, supporting inference of subtypes of\ninterpretable latent variables (e.g. diffusivity and reaction rates) from\nneuroimaging data. We evaluate our method on synthetic benchmarks and\ndemonstrate its potential for uncovering mechanistic subtypes of Alzheimer's\ndisease progression from positron emission tomography (PET) data.",
    "url": "http://arxiv.org/abs/2509.15124v1"
  },
  {
    "title": "Shedding Light on Dark Matter at the LHC with Machine Learning",
    "abstract": "We investigate a WIMP dark matter (DM) candidate in the form of a\nsinglino-dominated lightest supersymmetric particle (LSP) within the\n$Z_3$-symmetric Next-to-Minimal Supersymmetric Standard Model. This framework\ngives rise to regions of parameter space where DM is obtained via\nco-annihilation with nearby higgsino-like electroweakinos and DM direct\ndetection~signals are suppressed, the so-called ``blind spots\". On the other\nhand, collider signatures remain promising due to enhanced radiative decay\nmodes of higgsinos into the singlino-dominated LSP and a photon, rather than\ninto leptons or hadrons. This motivates searches for radiatively decaying\nneutralinos, however, these signals face substantial background challenges, as\nthe decay products are typically soft due to the small mass-splits ($\\Delta m$)\nbetween the LSP and the higgsino-like coannihilation partners. We apply a\ndata-driven Machine Learning (ML) analysis that improves sensitivity to these\nsubtle signals, offering a powerful complement to traditional search strategies\nto discover a new physics scenario. Using an LHC integrated luminosity of\n$100~\\mathrm{fb}^{-1}$ at $14~\\mathrm{TeV}$, the method achieves a $5\\sigma$\ndiscovery reach for higgsino masses up to $225~\\mathrm{GeV}$ with $\\Delta\nm\\!\\lesssim\\!12~\\mathrm{GeV}$, and a $2\\sigma$ exclusion up to\n$285~\\mathrm{GeV}$ with $\\Delta m\\!\\lesssim\\!20~\\mathrm{GeV}$. These results\nhighlight the power of collider searches to probe DM candidates that remain\nhidden from current direct detection experiments, and provide a motivation for\na search by the LHC collaborations using ML methods.",
    "url": "http://arxiv.org/abs/2509.15121v1"
  },
  {
    "title": "Efficient Conformal Prediction for Regression Models under Label Noise",
    "abstract": "In high-stakes scenarios, such as medical imaging applications, it is\ncritical to equip the predictions of a regression model with reliable\nconfidence intervals. Recently, Conformal Prediction (CP) has emerged as a\npowerful statistical framework that, based on a labeled calibration set,\ngenerates intervals that include the true labels with a pre-specified\nprobability. In this paper, we address the problem of applying CP for\nregression models when the calibration set contains noisy labels. We begin by\nestablishing a mathematically grounded procedure for estimating the noise-free\nCP threshold. Then, we turn it into a practical algorithm that overcomes the\nchallenges arising from the continuous nature of the regression problem. We\nevaluate the proposed method on two medical imaging regression datasets with\nGaussian label noise. Our method significantly outperforms the existing\nalternative, achieving performance close to the clean-label setting.",
    "url": "http://arxiv.org/abs/2509.15120v1"
  },
  {
    "title": "Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers",
    "abstract": "The growing demand for energy-efficient, high-performance AI systems has led\nto increased attention on alternative computing platforms (e.g., photonic,\nneuromorphic) due to their potential to accelerate learning and inference.\nHowever, integrating such physical components into deep learning pipelines\nremains challenging, as physical devices often offer limited expressiveness,\nand their non-differentiable nature renders on-device backpropagation difficult\nor infeasible. This motivates the development of hybrid architectures that\ncombine digital neural networks with reconfigurable physical layers, which\neffectively behave as black boxes. In this work, we present a framework for the\nend-to-end training of such hybrid networks. This framework integrates\nstochastic zeroth-order optimization for updating the physical layer's internal\nparameters with a dynamic low-rank surrogate model that enables gradient\npropagation through the physical layer. A key component of our approach is the\nimplicit projector-splitting integrator algorithm, which updates the\nlightweight surrogate model after each forward pass with minimal hardware\nqueries, thereby avoiding costly full matrix reconstruction. We demonstrate our\nmethod across diverse deep learning tasks, including: computer vision, audio\nclassification, and language modeling. Notably, across all modalities, the\nproposed approach achieves near-digital baseline accuracy and consistently\nenables effective end-to-end training of hybrid models incorporating various\nnon-differentiable physical components (spatial light modulators, microring\nresonators, and Mach-Zehnder interferometers). This work bridges hardware-aware\ndeep learning and gradient-free optimization, thereby offering a practical\npathway for integrating non-differentiable physical components into scalable,\nend-to-end trainable AI systems.",
    "url": "http://arxiv.org/abs/2509.15113v1"
  },
  {
    "title": "The Stellar Abundances and Galactic Evolution Survey (SAGES). IV. Surface Gravity Estimation and Giant-Dwarf Separation with the DDO51 Filter",
    "abstract": "Reliable estimation of stellar surface gravity (log $g$) for a large sample\nis crucial for evaluating stellar evolution models and understanding galactic\nstructure; However, it is not easy to accomplish due to the difficulty in\ngathering a large spectroscopic data set. Photometric sky survey using a\nspecific filter, on the other hand, can play a substantial role in the\nassessment of log $g$. The Stellar Abundances and Galactic Evolution Survey\n(SAGES) utilizes eight filters to provide accurate stellar parameters for\n$\\sim10^{7}$ stars, with its DDO51 intermediate-band filter specifically\ndesigned for robust log $g$ determination. In this work, the observed SAGES\n$u_{\\rm SC}$ and $v_{\\rm SAGES}$ photometry, the synthetic photometry in $g$,\n$r$, $i$, and DDO51 bands derived from \\textit{Gaia} XP spectra are employed to\ninvestigate the importance of the DDO51 filter in the determination of log $g$.\nWe applied machine-learning-based extinction correction and employed XGBoost\nmodels, trained on stellar parameters from LAMOST, to predict log $g$ using\nphotometric data. By comparing model predicted log $g$ with LAMOST values, we\nfind that including DDO51 filter improve the accuracies of log $g$ estimates by\n21.0\\% (from 0.224\\,dex to 0.177\\,dex) overall, and by 26.5\\% (from 0.302\\,dex\nto 0.222\\,dex ) for GK-type stars, as compared to those obtained without DDO51.\nThe DDO51 filter is also validated to be particularly effective for metal-poor\nstars ([Fe/H]$<$-1.0), where it significantly mitigates systematic biases. Our\nfindings highlight the diagnostic power of the SAGES DDO51 filter, providing\nenhanced stellar characterization vital for future in-depth studies of the\nMilky Way.",
    "url": "http://arxiv.org/abs/2509.15112v1"
  },
  {
    "title": "TDRM: Smooth Reward Models with Temporal Difference for LLM RL and Inference",
    "abstract": "Reward models are central to both reinforcement learning (RL) with language\nmodels and inference-time verification. However, existing reward models often\nlack temporal consistency, leading to ineffective policy updates and unstable\nRL training. We introduce TDRM, a method for learning smoother and more\nreliable reward models by minimizing temporal differences during training. This\ntemporal-difference (TD) regularization produces smooth rewards and improves\nalignment with long-term objectives. Incorporating TDRM into the actor-critic\nstyle online RL loop yields consistent empirical gains. It is worth noting that\nTDRM is a supplement to verifiable reward methods, and both can be used in\nseries. Experiments show that TD-trained process reward models (PRMs) improve\nperformance across Best-of-N (up to 6.6%) and tree-search (up to 23.7%)\nsettings. When combined with Reinforcement Learning with Verifiable Rewards\n(RLVR), TD-trained PRMs lead to more data-efficient RL -- achieving comparable\nperformance with just 2.5k data to what baseline methods require 50.1k data to\nattain -- and yield higher-quality language model policies on 8 model variants\n(5 series), e.g., Qwen2.5-(0.5B, 1,5B), GLM4-9B-0414, GLM-Z1-9B-0414,\nQwen2.5-Math-(1.5B, 7B), and DeepSeek-R1-Distill-Qwen-(1.5B, 7B). We release\nall code at https://github.com/THUDM/TDRM.",
    "url": "http://arxiv.org/abs/2509.15110v1"
  },
  {
    "title": "Learning Constraints from Stochastic Partially-Observed Closed-Loop Demonstrations",
    "abstract": "We present an algorithm for learning unknown parametric constraints from\nlocally-optimal input-output trajectory data. We assume that the given data is\ngenerated by demonstrators with stochastic nonlinear dynamics who execute a\nstate or output feedback law to robustly satisfy the constraints despite\nworst-case dynamics and output noise. We encode the Karush-Kuhn-Tucker (KKT)\nconditions of this robust optimal output feedback control problem within a\nfeasibility problem to recover constraints consistent with the local optimality\nof the demonstrations. We prove that our constraint learning method (i)\naccurately recovers the demonstrator's state or output feedback policy, and\n(ii) conservatively estimates the set of all state or output feedback policies\nthat ensure constraint satisfaction despite worst-case noise realizations.\nMoreover, we perform sensitivity analysis, proving that when demonstrations are\ncorrupted by transmission error, the inaccuracy in the learned state or output\nfeedback law scales linearly in the error magnitude. Our method accurately\nrecovers unknown constraints from simulated noisy, closed-loop demonstrations\ngenerated using dynamics, both linear and nonlinear, (e.g., unicycle and\nquadrotor) and a range of state and output feedback mechanisms.",
    "url": "http://arxiv.org/abs/2509.15109v1"
  },
  {
    "title": "Limitations of Public Chest Radiography Datasets for Artificial Intelligence: Label Quality, Domain Shift, Bias and Evaluation Challenges",
    "abstract": "Artificial intelligence has shown significant promise in chest radiography,\nwhere deep learning models can approach radiologist-level diagnostic\nperformance. Progress has been accelerated by large public datasets such as\nMIMIC-CXR, ChestX-ray14, PadChest, and CheXpert, which provide hundreds of\nthousands of labelled images with pathology annotations. However, these\ndatasets also present important limitations. Automated label extraction from\nradiology reports introduces errors, particularly in handling uncertainty and\nnegation, and radiologist review frequently disagrees with assigned labels. In\naddition, domain shift and population bias restrict model generalisability,\nwhile evaluation practices often overlook clinically meaningful measures. We\nconduct a systematic analysis of these challenges, focusing on label quality,\ndataset bias, and domain shift. Our cross-dataset domain shift evaluation\nacross multiple model architectures revealed substantial external performance\ndegradation, with pronounced reductions in AUPRC and F1 scores relative to\ninternal testing. To assess dataset bias, we trained a source-classification\nmodel that distinguished datasets with near-perfect accuracy, and performed\nsubgroup analyses showing reduced performance for minority age and sex groups.\nFinally, expert review by two board-certified radiologists identified\nsignificant disagreement with public dataset labels. Our findings highlight\nimportant clinical weaknesses of current benchmarks and emphasise the need for\nclinician-validated datasets and fairer evaluation frameworks.",
    "url": "http://arxiv.org/abs/2509.15107v1"
  },
  {
    "title": "Super-Linear: A Lightweight Pretrained Mixture of Linear Experts for Time Series Forecasting",
    "abstract": "Time series forecasting (TSF) is critical in domains like energy, finance,\nhealthcare, and logistics, requiring models that generalize across diverse\ndatasets. Large pre-trained models such as Chronos and Time-MoE show strong\nzero-shot (ZS) performance but suffer from high computational costs. In this\nwork, We introduce Super-Linear, a lightweight and scalable mixture-of-experts\n(MoE) model for general forecasting. It replaces deep architectures with simple\nfrequency-specialized linear experts, trained on resampled data across multiple\nfrequency regimes. A lightweight spectral gating mechanism dynamically selects\nrelevant experts, enabling efficient, accurate forecasting. Despite its\nsimplicity, Super-Linear matches state-of-the-art performance while offering\nsuperior efficiency, robustness to various sampling rates, and enhanced\ninterpretability. The implementation of Super-Linear is available at\n\\href{https://github.com/azencot-group/SuperLinear}{https://github.com/azencot-group/SuperLinear}",
    "url": "http://arxiv.org/abs/2509.15105v1"
  },
  {
    "title": "Vulnerable Agent Identification in Large-Scale Multi-Agent Reinforcement Learning",
    "abstract": "Partial agent failure becomes inevitable when systems scale up, making it\ncrucial to identify the subset of agents whose compromise would most severely\ndegrade overall performance. In this paper, we study this Vulnerable Agent\nIdentification (VAI) problem in large-scale multi-agent reinforcement learning\n(MARL). We frame VAI as a Hierarchical Adversarial Decentralized Mean Field\nControl (HAD-MFC), where the upper level involves an NP-hard combinatorial task\nof selecting the most vulnerable agents, and the lower level learns worst-case\nadversarial policies for these agents using mean-field MARL. The two problems\nare coupled together, making HAD-MFC difficult to solve. To solve this, we\nfirst decouple the hierarchical process by Fenchel-Rockafellar transform,\nresulting a regularized mean-field Bellman operator for upper level that\nenables independent learning at each level, thus reducing computational\ncomplexity. We then reformulate the upper-level combinatorial problem as a MDP\nwith dense rewards from our regularized mean-field Bellman operator, enabling\nus to sequentially identify the most vulnerable agents by greedy and RL\nalgorithms. This decomposition provably preserves the optimal solution of the\noriginal HAD-MFC. Experiments show our method effectively identifies more\nvulnerable agents in large-scale MARL and the rule-based system, fooling system\ninto worse failures, and learns a value function that reveals the vulnerability\nof each agent.",
    "url": "http://arxiv.org/abs/2509.15103v1"
  },
  {
    "title": "Digital Twin-based Cooperative Autonomous Driving in Smart Intersections: A Multi-Agent Reinforcement Learning Approach",
    "abstract": "Unsignalized intersections pose safety and efficiency challenges due to\ncomplex traffic flows and blind spots. In this paper, a digital twin (DT)-based\ncooperative driving system with roadside unit (RSU)-centric architecture is\nproposed for enhancing safety and efficiency at unsignalized intersections. The\nsystem leverages comprehensive bird-eye-view (BEV) perception to eliminate\nblind spots and employs a hybrid reinforcement learning (RL) framework\ncombining offline pre-training with online fine-tuning. Specifically, driving\npolicies are initially trained using conservative Q-learning (CQL) with\nbehavior cloning (BC) on real datasets, then fine-tuned using multi-agent\nproximal policy optimization (MAPPO) with self-attention mechanisms to handle\ndynamic multi-agent coordination. The RSU implements real-time commands via\nvehicle-to-infrastructure (V2I) communications. Experimental results show that\nthe proposed method yields failure rates below 0.03\\% coordinating up to three\nconnected autonomous vehicles (CAVs), significantly outperforming traditional\nmethods. In addition, the system exhibits sub-linear computational scaling with\ninference times under 40 ms. Furthermore, it demonstrates robust generalization\nacross diverse unsignalized intersection scenarios, indicating its practicality\nand readiness for real-world deployment.",
    "url": "http://arxiv.org/abs/2509.15099v1"
  }
]